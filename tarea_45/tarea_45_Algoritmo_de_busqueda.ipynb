{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[Algoritmo de búsqueda A*](https://es.wikipedia.org/wiki/Algoritmo_de_b%C3%BAsqueda_A*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una nota sobre la notación Big-O\n",
    "\n",
    "Es útil saber lo rápido que es un algoritmo y el espacio que necesita. Esto te permite elegir el algoritmo adecuado para el trabajo.\n",
    "\n",
    "La notación Big-O te da una indicación aproximada del tiempo de ejecución de un algoritmo y la cantidad de memoria que utiliza. Cuando alguien dice: \"Este algoritmo tiene un tiempo de ejecución en el peor de los casos de **$$O(n^2)$$** y utiliza **$$O(n)$$** de espacio\", quiere decir que es un poco lento pero no necesita mucha memoria adicional.\n",
    "\n",
    "La determinación del Big-O de un algoritmo suele hacerse mediante un análisis matemático. Aquí nos saltamos las matemáticas, pero es útil saber lo que significan los diferentes valores, así que aquí tienes una tabla muy útil. **$n$** se refiere al número de elementos de datos que estás procesando. Por ejemplo, al ordenar un array de 100 elementos, **$$n = 100$$**.\n",
    "\n",
    "Big-O | Nombre | Descripción\n",
    "------| ---- | -----------\n",
    "**$O(1)$** | constante | **Este es el mejor.** El algoritmo siempre toma la misma cantidad de tiempo, independientemente de la cantidad de datos que haya. Ejemplo: buscar un elemento de un array por su índice.  \n",
    "**$$O(log n)$$** | logarithmic | **Pretty great.** Este tipo de algoritmos reduce a la mitad la cantidad de datos en cada iteración. Si tienes 100 elementos, tardas unos 7 pasos en encontrar la respuesta. Con 1.000 elementos, se necesitan 10 pasos. Y con 1.000.000 elementos sólo se necesitan 20 pasos. Esto es súper rápido incluso para grandes cantidades de datos. Ejemplo: búsqueda binaria.  \n",
    "**$O(n)$** | linear | **Good performance.** Si tienes 100 elementos, esto hace 100 unidades de trabajo. Si se duplica el número de elementos, el algoritmo tarda exactamente el doble (200 unidades de trabajo). Ejemplo: búsqueda secuencial.  \n",
    "**$O(n log n)$** | \"linearithmic\" | **Rendimiento decente.** Es ligeramente peor que el lineal, pero no demasiado malo. Ejemplo: los algoritmos de ordenación de propósito general más rápidos.\n",
    "**$O(n^2)$** | cuadrático | **Muy lento.** Si tienes 100 elementos, esto hace $100^2$ = 10.000 unidades de trabajo. Si se duplica el número de elementos, es cuatro veces más lento (porque 2 al cuadrado es igual a 4). Ejemplo: algoritmos que utilizan bucles anidados, como la ordenación por inserción.\n",
    "**$O(n^3)$** | cúbico | **Poco rendimiento.** Si tienes 100 elementos, esto hace $100^3$ = 1.000.000 de unidades de trabajo. Duplicar el tamaño de la entrada lo hace ocho veces más lento. Ejemplo: multiplicación de matrices.\n",
    "**$O(2^n)$** | exponential | **Very poor performance.** Se quiere evitar este tipo de algoritmos, pero a veces no hay más remedio. Añadir un solo bit a la entrada duplica el tiempo de ejecución. Ejemplo: problema del vendedor ambulante.\n",
    "**$O(n!)$** | factorial | **Intolerablemente lento.** Tarda literalmente un millón de años en hacer algo.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparison of Big O computations](https://upload.wikimedia.org/wikipedia/commons/7/7e/Comparison_computational_complexity.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se presentan algunos ejemplos para cada categoría de rendimiento:\n",
    "\n",
    "**$O(1)$**\n",
    "\n",
    "  El ejemplo más común con complejidad O(1) es el acceso a un índice de matriz.\n",
    "\n",
    "  ```swift\n",
    "  let value = array[5]\n",
    "  ```\n",
    "\n",
    "  Otro ejemplo de $O(1)$ es el de empujar y sacar de la pila."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(log n)$**\n",
    "\n",
    "  ```swift\n",
    "  var j = 1\n",
    "  while j < n {\n",
    "    // do constant time stuff\n",
    "    j *= 2\n",
    "  }\n",
    "  ```  \n",
    "\n",
    "  En lugar de simplemente incrementarse, 'j' se incrementa 2 veces en cada ejecución.\n",
    "\n",
    "  El algoritmo de búsqueda binaria es un ejemplo de complejidad O(log n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(n)$**\n",
    "\n",
    "  ```swift\n",
    "  for i in stride(from: 0, to: n, by: 1) {\n",
    "    print(array[i])\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  El recorrido de matrices y la búsqueda lineal son ejemplos de complejidad $O(n)$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(n log n)$**\n",
    "\n",
    "  ```swift\n",
    "  for i in stride(from: 0, to: n, by: 1) {\n",
    "  var j = 1\n",
    "    while j < n {\n",
    "      j *= 2\n",
    "      // do constant time stuff\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  O\n",
    "\n",
    "  ```swift\n",
    "  for i in stride(from: 0, to: n, by: 1) {\n",
    "    func index(after i: Int) -> Int? { // multiplies `i` by 2 until `i` >= `n`\n",
    "      return i < n ? i * 2 : nil\n",
    "    }\n",
    "    for j in sequence(first: 1, next: index(after:)) {\n",
    "      // do constant time stuff\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  Merge Sort y Heap Sort son ejemplos de complejidad $O(n log n)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(n^2)$**\n",
    "\n",
    "  ```swift\n",
    "  for i  in stride(from: 0, to: n, by: 1) {\n",
    "    for j in stride(from: 1, to: n, by: 1) {\n",
    "      // do constant time stuff\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  Recorrer una matriz bidimensional simple y ordenar burbujas son ejemplos de complejidad $O(n^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(n^3)$**\n",
    "\n",
    "  ```swift\n",
    "  for i in stride(from: 0, to: n, by: 1) {\n",
    "    for j in stride(from: 1, to: n, by: 1) {\n",
    "      for k in stride(from: 1, to: n, by: 1) {\n",
    "        // do constant time stuff\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  ```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(2^n)$**\n",
    "\n",
    "  Los algoritmos con tiempo de ejecución O(2^N) suelen ser algoritmos recursivos que resuelven un problema de tamaño N resolviendo recursivamente dos problemas más pequeños de tamaño N-1.\n",
    "  El siguiente ejemplo imprime todos los movimientos necesarios para resolver el famoso problema de las \"Torres de Hanoi\" para N discos.\n",
    "\n",
    "  ```swift\n",
    "  func solveHanoi(n: Int, from: String, to: String, spare: String) {\n",
    "    guard n >= 1 else { return }\n",
    "    if n > 1 {\n",
    "        solveHanoi(n: n - 1, from: from, to: spare, spare: to)\n",
    "        solveHanoi(n: n - 1, from: spare, to: to, spare: from)\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$O(n!)$**\n",
    "\n",
    "  El ejemplo más trivial de una función que requiere un tiempo $O(n!)$ se da a continuación.\n",
    "\n",
    "  ```swift\n",
    "  func nFactFunc(n: Int) {\n",
    "    for i in stride(from: 0, to: n, by: 1) {\n",
    "      nFactFunc(n: n - 1)\n",
    "    }\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo no es necesario recurrir a las matemáticas para averiguar cuál es el Big-O de un algoritmo, sino que basta con utilizar la intuición. Si tu código utiliza un único bucle que mira todos los **$n$** elementos de tu entrada, el algoritmo es **$O(n)$**. Si el código tiene dos bucles anidados, es **O$(n^2)$**. Tres bucles anidados dan **$O(n^3)$**, y así sucesivamente.\n",
    "\n",
    "Tenga en cuenta que la notación Big-O es una estimación y sólo es realmente útil para valores grandes de **n**. Por ejemplo, el tiempo de ejecución en el peor de los casos para el algoritmo [insertion sort](Insertion%20Sort/) es **$O(n^2)$**. En teoría, esto es peor que el tiempo de ejecución de [merge sort](Merge%20Sort/), que es **$O(n log n)$**. Pero para pequeñas cantidades de datos, la ordenación por inserción es realmente más rápida, especialmente si el array ya está parcialmente ordenado.\n",
    "\n",
    "Si encuentras esto confuso, no dejes que este asunto del Big-O te moleste demasiado. Es útil sobre todo cuando se comparan dos algoritmos para averiguar cuál es mejor. Pero al final, lo que quieres es probar en la práctica cuál es realmente el mejor. Y si la cantidad de datos es relativamente pequeña, incluso un algoritmo lento será lo suficientemente rápido para su uso práctico.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
